seed: 0
device: None                              # Set to 'cpu' or 'cuda' to override automatic device selection

logging:
  log_dir: ''                            # Use optuna's log directory if empty
  log_every_n_steps: 10
  visualize_every_n_steps: 500
  num_logged_samples: 4
  checkpoint_every_n_epochs: 10
  keep_n_checkpoints: 1
  checkpoint: True
  debug: False

nef:
  num_in: -1                              # Automatically derived from the dataset
  num_out: -1                             # Automatically derived from the dataset

  num_self_att_layers: 0
  num_hidden: 128
  num_heads: 2
  condition_value_transform: True
  condition_invariant_embedding: True

  latent_dim: 64
  num_latents: 144
  top_k: 9
  gaussian_window: -1                          # If None gaussian window is not used, if -1 the value is set proportional to the number of latents.
  optimize_gaussian_window: False              # If True, the gaussian window size is optimized during training

  embedding_type: rff                          # Choices, 'rff', 'polynomial', 'ffn'
  embedding_freq_multiplier_invariant: 0.1     # For RFF the 1/std and for polynomial the degree
  embedding_freq_multiplier_value: 2           # For RFF the 1/std and for polynomial the degree
  invariant_type: rel_pos                      # Choices: 'rel_pos', 'norm_rel_pos', 'abs_pos', 'ponita', 'rel_pos_periodic'

# Training configuration
training:
  num_epochs: 5000
  max_num_sampled_points: 1024

# Testing configuration
test:
  test_interval: 100
  min_num_epochs: 100

# Dataset configuration
dataset:
  name: stl10
  batch_size: 8
  path: './data'
  num_signals_train: 5000
  num_signals_test: 1000
  num_workers: 0
  image_shape: -1

# Arguments specific to autodecoding
optimizer:
  name: adamw
  learning_rate_enf: 1e-4
  learning_rate_codes: 0
